tiramisu:
    tiramisu_path: "path to tiramisu root directory" 
    env_type:  "model"
    tags_model_weights: "<Your path to the repo>/env_api/scheduler/models/model_release_version.pt"

dataset:
    dataset_format: HYBRID | PICKLE 
    cpps_path: "path to cpp files or cpp pickle file"
    dataset_path: "path to dataset pkl file"
    save_path: "path to save updated or new dataset"
    shuffle: False/True # Whether to shuffle the dataset
    seed: null # Seed for shuffle
    saving_frequency: 10000 # dataset save to disk frequency
    # When doing evaluation on the benchmark set the value to True
    is_benchmark: False
    benchmark_cpp_files: 'path to cpp folder of benchmarks'
    benchmark_dataset_path: 'path to pkl file of benchmarks of available'

ray:
    results: "path to where you want to store ray results"
    restore_checkpoint: "path of the checkpoint you want to restore"

experiment:
    name: "test"
    checkpoint_frequency: 10
    checkpoint_num_to_keep: 10
    # The following 3 values are the values to stop the experiment if any of them is reached 
    training_iteration: 500
    timesteps_total: 1000000
    episode_reward_mean: 2
    # Use this value to punish or tolerate illegal actions from being taken
    legality_speedup: 1.0
    # Use the order of beam search 
    beam_search_order : True
    entropy_coeff: 0.1
    # Training parameters
    train_batch_size: 1024
    lr: 0.00005

policy_network:
    # Set this to True if you want to use shared weights between policy and value function
    vf_share_layers: False
    policy_hidden_layers: 
        - 2048
        - 512 
        - 64
    # If vf_share_layers is true then, these values won't be taken for the value network
    vf_hidden_layers: 
        - 512 
        - 64
    dropout_rate: 0.2
    